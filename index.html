<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="One-Step Flow Matching for Human Trajectory Forecasting via Implicit Maximum Likelihood Estimation based Distillation">
    <meta name="keywords" content="Diffusion distillation,IMLE,flow matching">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>MoFlow: One-Step Flow Matching for Human Trajectory Forecasting via Implicit Maximum Likelihood Estimation
        based Distillation</title>
    <style>
        /* Apply cool gradient to the "MoFlow" part */
        .gradient-text {
            background: linear-gradient(to right, cyan, magenta);
            -webkit-background-clip: text;
            background-clip: text;
            color: transparent;
            font-weight: bold;
        }

        .math-circle {
            display: flex;
            align-items: center;
            justify-content: center;
            width: 80px;
            height: 80px;
            border-radius: 50%;
            background-color: #f5f5f5;
            font-size: 1.5rem;
            font-weight: bold;
            margin: 0 auto 10px auto;
            border: 2px solid #333;
        }
    </style>

    <!-- Latex -->
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>

    <!-- Define nav bars  -->
    <nav class="navbar" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
            <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu">
            <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
                <a class="navbar-item" href="https://felix-yuxiang.github.io/">
                    <span class="icon">
                        <i class="fas fa-home"></i>
                    </span>
                </a>

                <div class="navbar-item has-dropdown is-hoverable">
                    <a class="navbar-link">
                        More Research
                    </a>
                    <div class="navbar-dropdown">
                        <a class="navbar-item">
                            Coming Soon...
                        </a>
                    </div>
                </div>
            </div>

        </div>
    </nav>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-2 publication-title"> <span class="gradient-text">MoFlow</span>: One-Step
                            Flow Matching for Human Trajectory Forecasting via Implicit Maximum Likelihood Estimation
                            based Distillation</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://felix-yuxiang.github.io/">Yuxiang Fu</a><sup>1,2,*</sup>,</span>
                            <span class="author-block">
                                <a href="https://qiyan98.github.io/">Qi Yan</a><sup>1,2,*</sup>,</span>
                            <span class="author-block">
                                <a href="https://sites.google.com/site/wanglele1986/">Lele Wang</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.sfu.ca/~keli/">Ke Li</a><sup>3</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://lrjconan.github.io/">Renjie Liao</a><sup>1,2,4</sup>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>University of British Columbia,</span>
                            <span class="author-block"><sup>2</sup>Vector Institute for AI,</span>
                            <span class="author-block"><sup>3</sup>Simon Fraser University,</span>
                            <span class="author-block"><sup>4</sup>Canada CIFAR AI Chair</span>
                            <br> <span class="author-block" style="color: red">Computer Vision and Pattern Recognition
                                Conference (CVPR) 2025</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/pdf/2503.09950"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2503.09950"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="https://github.com/felix-yuxiang/MoFlow"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>

                                <!-- Video Link. -->
                                <span class="link-block">
                                    <a href="" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-youtube"></i>
                                        </span>
                                        <span>Video</span>
                                    </a>
                                </span>
                                <!-- Dataset Link. -->
                                <!-- <span class="link-block">
                <a href="https://github.com/felix-yuxiang/MoFlow"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Human trajectory forecasting poses a challenge to predict the inherently multi-modal future
                            movements of individuals based on their past trajectories and relevant contextual cues.
                        </p>
                        <p>
                            We tackle this challenge by proposing a novel <b>Mo</b>tion prediction conditional
                            <b>Flow</b> matching model, termed <span class="gradient-text">MoFlow</span>, to generate
                            K-shot future trajectories for all agents in a given scene.
                            Additionally, we design a novel flow matching loss function that not only ensures at least
                            one of the \( K \) sets of future trajectories is accurate but also encourages all \(K\)
                            sets of future trajectories to be diverse and plausible.
                        </p>
                        <p>
                            Furthermore, by leveraging the <b>Implicit Maximum Likelihood Estimation</b> (IMLE), we
                            propose a novel distillation method for flow models that only requires samples from the
                            teacher model.
                        </p>
                        <p>
                            Extensive experiments on the real-world datasets, including <b>SportVU NBA games, ETH-UCY,
                                and SDD</b>, demonstrate that both our teacher flow model and the IMLE-distilled student
                            model achieve state-of-the-art performance. These models can generate diverse trajectories
                            that are physically and socially plausible.
                            Moreover, our one-step student model is <b>100</b> times faster than the teacher flow model
                            during sampling. &#128640;&#128640;&#128640;
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->
    </section>

    <!-- Put a mp4 video here with title main framework, make it center -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column is-flex is-flex-direction-column is-align-items-center">
                    <h2 class="title is-3">Main Framework</h2>
                    <video id="main-framework" controls loop playsinline height="100%">
                        <source src="./static/videos/MoFlow-IMLE-video.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>
    </section>


    <section class="section">
        <div class="container is-max-desktop">

            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">Flow Matching in <span class="gradient-text">MoFlow</span></h2>

                    <!-- Forward and backward process. -->
                    <div class="content has-text-justified">
                        <p>In terms of the forward process in flow matching, we adopt a simple linear interpolation between the clean trajectories \(Y^1\sim q\) and pure noise \(Y^0\sim \mathcal{N}(\mathbf{0},\mathbf{I})\),
                            <div class="math-block">
                                \[
                                Y^t = (1-t)Y^0 + tY^1 \qquad t \in [0, 1].
                                \]
                            </div>
                            The reverse process, which allows us to generate new samples, is described by the ordinary differential equation
                            <div class="math-block">
                                \[
                                d Y^t = v_\theta(Y^t, t, C)dt.
                                \]
                            </div>
                            Here, \(v_\theta\) represents the parametrized vector field that approximates the straight flow \(U^t=Y^1-Y^0\). Note that \(C\) entails all the contextual information of agents in a scene.
                        </p>
                        <p>
                            We can simulate the forward and backward process of flow matching by animating the
                            transition a single trajectory between noise and data. Use the slider here to visualize the
                            trajectory at different flow matching time step between noise distribution \(Y^0\) and data
                            distribution \(Y^1\). Check out our paper to see how we train and sample from the conditional flow-matching model.

                        </p>
                    </div>

                    <div class="columns is-vcentered interpolation-panel">
                        <!-- Start Frame -->
                        <div class="column is-3 has-text-centered">
                            <div class="math-circle">\( Y^1 \)</div>
                            <img src="./static/images/interpolate_start.jpg" class="interpolation-image"
                                alt="Interpolate start reference image." />
                            <p>Clean trajectory</p>
                        </div>

                        <!-- Interpolation slider -->
                        <div class="column interpolation-video-column">
                            <div id="interpolation-image-wrapper">
                                Loading...
                            </div>
                            <input class="slider is-fullwidth is-large is-info" id="interpolation-slider" step="1"
                                min="0" max="100" value="0" type="range">
                        </div>

                        <!-- End Frame -->
                        <div class="column is-3 has-text-centered">
                            <div class="math-circle">\( Y^0 \)</div>
                            <img src="./static/images/interpolate_end.jpg" class="interpolation-image"
                                alt="Interpolation end reference image." />
                            <p class="is-bold">Noisy trajectory</p>
                        </div>
                    </div>

                    <br />
                    <!--/ Forward and backward process. -->
                </div>
            </div>
            <!--/ Animation. -->


            <!-- Video Presentation. -->
            <!-- <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Video Presentation</h2>
          <div class="publication-video">
            <iframe src="..."
                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
    </div> -->
            <!-- <div class="columns is-centered has-text-centered">
        <div class="column">
            <div class="content has-text-justified">
                <p>
                    You can find more examples in the main paper and the supplementary material.
                </p>
            </div>
        </div>
    </div>
  </div> -->
    </section>

    <!-- MoFlow objective-->
     <section class="section">
        <div class="container is-max-desktop">
            <h2 class="title is-3">A novel <span class="gradient-text">MoFlow</span> objective</h2>
            <div class="content has-text-justified">
                <p>By rearranging the original linear flow objective, we introduce a neural network \(D_\theta:=Y^t+(1-t)v_\theta(Y^t, C, t) \) that matches the future trajectory \(Y^1\) in the data space and the objective turns into
                    <div class="math-block">
                        \[
                        \mathcal{L}_{\text{FM}} = \mathbb{E}_{Y^t, Y^1\sim q, t\sim \mathcal{U}[0,1]} \left[ \frac{\| D_{\theta}(Y^t, C, t) - Y^1 \|_2^2}{(1 - t)^2} \right].
                        \]
                    </div> 
                    To promote the multi-modality of the future trajectory, we design a novel loss function. Specifically, our \(D_\theta\) generates \(K\) scene-level correlated waypoint predictions, denoted by \(\{S_i\}^K_{i=1}\), alongside
                    corrresponding classification logits \(\{\zeta_i\}_{i=1}^K\). For simplicity, we omit the time-dependent coefficient and obtain a new loss \(\bar{\mathcal{L}}_{\text{FM}}\)
                    <div class="math-block">
                        \[
                        \bar{\mathcal{L}}_{\text{FM}} = \mathbb{E}_{Y^t, Y^1\sim q, t\sim \mathcal{U}[0,1]} \left[ \| S_{j^*} - Y^1 \|_2^2 + \text{CE}(\zeta_{1:K}, j^*) \right]
                        \]
                    </div> where \(j^* = \arg\min_{j} \| S_j - Y^1 \|_2^2\) and \(\text{CE}(\cdot,\cdot)\) is the cross-entropy loss.
                </p>
            </div>
        </div>
     </section>

    <!-- IMLE -->
    <section class="section">
        <div class="container is-max-desktop">
            <h2 class="title is-3">IMLE Module</h2>
    
            <div class="columns is-vcentered is-variable is-6 is-multiline">
                <!-- Image Column (Left, full width on mobile) -->
                <div class="column is-full-mobile is-one-third-tablet is-one-third-desktop">
                    <figure class="image">
                        <img src="static/images/IMLE_algorithm.png" alt="IMLE Algorithm Diagram" style="width: 100%; height: auto; margin-bottom: 3rem;">
                        <img src="static/images/IMLE_overview.png" alt="">
                    </figure>
                </div>
    
                <!-- Text Column (Right, full width on mobile) -->
                <div class="column is-full-mobile is-two-thirds-tablet is-two-thirds-desktop">
                    <div class="content">
                        <p>
                            The IMLE distillation process is outlined in <code>Algorithm 1</code>.
                            Specifically, lines 4–6 describe the standard ODE-based sampling of the teacher model, <span class="gradient-text">MoFlow</span>. This produces \( K \) correlated multi-modal trajectory predictions
                            \( \hat{Y}^1_{1:K} \) conditioned on the context \( C \). A conditional IMLE generator \( G_\phi \) then uses a noise
                            vector \( Z \) and context \( C \) to generate \( K \)-component trajectories
                            \( \Gamma \), matching the shape of \( \hat{Y}^1_{1:K} \).
                        </p>
    
                        <p>
                            The conditional IMLE objective generates <b>more</b> samples than those in the distillation dataset for the same context \( C \).
                            Specifically, \( m \) i.i.d. samples are drawn via \( G_\phi \), and the one closest to the teacher prediction \( \hat{Y}^1_{1:K} \) is selected for loss computation.
                            This minimizes the distance to the nearest student sample, ensuring the teacher model’s mode is well-approximated.
                        </p>
    
                        <p>
                            To preserve trajectory prediction multi-modality, we employ the Chamfer distance as the loss function
                        </p>
    
                        <div class="math-block">
                            \[
                            \mathcal{L}_{\text{IMLE}}(\hat{Y}^1_{1:K}, \Gamma) = \dfrac{1}{K} \left( \sum_{i=1}^K \min_j \|\hat{Y}^1_i - \Gamma^{(j)}\| + \sum_{j=1}^K \min_i \|\hat{Y}^1_i - \Gamma^{(j)}\| \right),
                            \]
                        </div>
    
                        <p>
                            where \( \Gamma^{(i)} \in \mathbb{R}^{A \times 2T_f} \) is the \( i \)-th component of the IMLE-generated correlated trajectory.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    

<!-- NBA -->
    <section class="hero is-light is-small">
        <div class="hero-body">
            <h2 class="title is-3 has-text-centered">Animation on NBA SportVU dataset</h2>
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">

                    <!-- Scene 0 Agent 0 -->
                    <div class="item item-00">
                        <div class="container is-max-desktop">
                            <div class="video-wrapper"
                                style="overflow: hidden; position: relative; padding-top: 56.25%;">
                                <video muted loop playsinline controls
                                    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
                                    <source src="./static/videos/scene_0_agent_0.mp4" type="video/mp4">
                                </video>
                            </div>
                        </div>
                    </div>

                    <!-- Scene 2 Agent 8 -->
                    <div class="item item-28">
                        <div class="container is-max-desktop">
                            <div class="video-wrapper"
                                style="overflow: hidden; position: relative; padding-top: 56.25%;">
                                <video muted loop playsinline controls
                                    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
                                    <source src="./static/videos/scene_2_agent_8.mp4" type="video/mp4">
                                </video>
                            </div>
                        </div>
                    </div>

                    <!-- Scene 3 Agent 0 -->
                    <div class="item item-30">
                        <div class="container is-max-desktop">
                            <div class="video-wrapper"
                                style="overflow: hidden; position: relative; padding-top: 56.25%;">
                                <video muted loop playsinline controls
                                    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
                                    <source src="./static/videos/scene_3_agent_0.mp4" type="video/mp4">
                                </video>
                            </div>
                        </div>
                    </div>

                    <!-- Scene 4 Agent 2 -->
                    <div class="item item-42">
                        <div class="container is-max-desktop">
                            <div class="video-wrapper"
                                style="overflow: hidden; position: relative; padding-top: 56.25%;">
                                <video muted loop playsinline controls
                                    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
                                    <source src="./static/videos/scene_4_agent_2.mp4" type="video/mp4">
                                </video>
                            </div>
                        </div>
                    </div>

                    <!-- Scene 4 Agent 5 -->
                    <div class="item item-45">
                        <div class="container is-max-desktop">
                            <div class="video-wrapper"
                                style="overflow: hidden; position: relative; padding-top: 56.25%;">
                                <video muted loop playsinline controls
                                    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
                                    <source src="./static/videos/scene_4_agent_5.mp4" type="video/mp4">
                                </video>
                            </div>
                        </div>
                    </div>

                    <!-- Scene 4 Agent 10 -->
                    <div class="item item-410">
                        <div class="container is-max-desktop">
                            <div class="video-wrapper"
                                style="overflow: hidden; position: relative; padding-top: 56.25%;">
                                <video muted loop playsinline controls
                                    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
                                    <source src="./static/videos/scene_4_agent_10.mp4" type="video/mp4">
                                </video>
                            </div>
                        </div>
                    </div>

                    <!-- Scene 5 Agent 8 -->
                    <div class="item item-58">
                        <div class="container is-max-desktop">
                            <div class="video-wrapper"
                                style="overflow: hidden; position: relative; padding-top: 56.25%;">
                                <video muted loop playsinline controls
                                    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
                                    <source src="./static/videos/scene_5_agent_8.mp4" type="video/mp4">
                                </video>
                            </div>
                        </div>
                    </div>

                    <!-- Scene 5 Agent 10 -->
                    <div class="item item-510">
                        <div class="container is-max-desktop">
                            <div class="video-wrapper"
                                style="overflow: hidden; position: relative; padding-top: 56.25%;">
                                <video muted loop playsinline controls
                                    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
                                    <source src="./static/videos/scene_5_agent_10.mp4" type="video/mp4">
                                </video>
                            </div>
                        </div>
                    </div>

                </div>
            </div>
            <p class="subtitle has-text-centered" style="margin-top: 1.5rem;margin-bottom: 3rem;">From left to right, the results displayed correspond to <b>Leapfrog Diffusion,  <span class="gradient-text">MoFlow</span>, <span class="gradient-text">MoFlow</span>-IMLE</b> respectively.</p>
        </div>
    </section>

    <!-- ETH-UCY -->
    <section class="hero is-dark">
        <div class="hero-body">
          <div class="container">
            <h2 class="title is-3 has-text-centered" style="margin-bottom: 3rem;">Animation on ETH-UCY dataset</h2>
            <div class="columns is-gapless is-mobile">
              <div class="column has-text-centered">
                <video 
                  controls 
                  loop 
                  playsinline>
                  <source src="static/videos/eth_moflow_1_1050.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <video 
                  controls 
                  loop 
                  playsinline>
                  <source src="static/videos/eth_hotel_moflow_11_540.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <video 
                  controls 
                  loop 
                  playsinline>
                  <source src="static/videos/eth_zara1_moflow_5_50.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <video 
                  controls 
                  loop 
                  playsinline>
                  <source src="static/videos/eth_zara2_moflow_7_80.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <p style="font-size: 2rem;"><span class="gradient-text">MoFlow</span></p>
              </div>
              <div class="column has-text-centered">
                <video 
                  controls 
                  loop 
                  playsinline>
                  <source src="static/videos/eth_imle_19_1050.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <video 
                  controls 
                  loop 
                  playsinline>
                  <source src="static/videos/eth_hotel_imle_19_540.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <video 
                  controls 
                  loop 
                  playsinline>
                  <source src="static/videos/eth_zara1_imle_19_50.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <video 
                  controls 
                  loop 
                  playsinline>
                  <source src="static/videos/eth_zara2_imle_19_80.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <p style="font-size: 2rem;"><span class="gradient-text">MoFlow</span>-IMLE</p>
              </div>
            </div>
          </div>
        </div>
      </section>

    <!-- Bibtex reference -->

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@inproceedings{fu2025moflowonestepflowmatching,
  author    = {Fu, Yuxiang and Yan, Qi and Wang, Lele and Li, Ke and Liao, Renjie},
  title     = {MoFlow: One-Step Flow Matching for Human Trajectory Forecasting via Implicit Maximum Likelihood Estimation based Distillation},
  journal   = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year      = {2025},
}</code></pre>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="https://arxiv.org/pdf/2503.09950">
                    <i class="fas fa-file-pdf"></i>
                </a>
                <a class="icon-link" href="https://github.com/felix-yuxiang" class="external-link" disabled>
                    <i class="fab fa-github"></i>
                </a>
                <a class="icon-link" href="https://felix-yuxiang.github.io">
                    <i class="fas fa-home"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        This page was built using the <a
                            href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                            target="_blank">Academic Project Page Template</a> which was adopted by the&nbsp;<a
                            href="https://nerfies.github.io" target="_blank">Nerfies</a>&nbsp;project page.
                        <br> This website is licensed under a <a rel="license"
                            href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                            Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>